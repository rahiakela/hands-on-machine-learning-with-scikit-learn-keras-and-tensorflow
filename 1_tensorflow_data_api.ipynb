{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1-tensorflow-data-api.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyONKmIa7WnSy5GDk/jEs42h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/hands-on-machine-learning-with-scikit-learn-keras-and-tensorflow/blob/13-loading-and-preprocessing-data-with-tensorflow/1_tensorflow_data_api.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gffXA1BL54_S",
        "colab_type": "text"
      },
      "source": [
        "# Loading and Preprocessing Data with TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWhm5Orq6O_p",
        "colab_type": "text"
      },
      "source": [
        "Ingesting a large dataset and preprocessing it efficiently can be tricky to implement with other **Deep Learning** libraries, but **TensorFlow** makes it easy thanks to the **Data API**: you just create a dataset object, tell it where to get the data, then transform it in any way you want, and **TensorFlow** takes care of all the implementation details, such as multithreading, queuing, batching, prefetching, and so on.\n",
        "\n",
        "Off the shelf, the **Data API** can read from text files (such as CSV files), binary files with fixed-size records, and binary files that use **TensorFlow’s TFRecord format**, which supports records of varying sizes. TFRecord is a flexible and efficient binary format based on Protocol Buffers (an open source binary format). \n",
        "\n",
        "The **Data API** also has support for reading from SQL databases. Moreover, many Open Source extensions are available to read from all sorts of data sources, such as **Google’s BigQuery** service.\n",
        "\n",
        "However, reading huge datasets efficiently is not the only difficulty: the data also needs to be preprocessed. Indeed, it is not always composed strictly of convenient numerical fields: sometimes there will be text features, categorical features, and so on.\n",
        "\n",
        "To handle this, TensorFlow provides the **Features API**: it lets you easily convert these\n",
        "features to numerical features that can be consumed by your neural network. \n",
        "\n",
        "For example, categorical features with a large number of categories (such as cities, or words) can be encoded using embeddings (an embedding is a trainable dense vector that represents a category).\n",
        "\n",
        "**Data API** cover the **TFRecord format** and the **Features\n",
        "API** that is related to  these projects.\n",
        "\n",
        "* **TF Transform (tf.Transform)** makes it possible to write a single preprocessing function that can be run both in batch mode on your full training set, before training (to speed it up), and then exported to a TF Function and incorporated into your trained model, so that once it is deployed in production, it can take care of preprocessing new instances on the fly.\n",
        "* **TF Datasets (TFDS)** provides a convenient function to download many common datasets of all kinds, including large ones like **ImageNet**, and it provides convenient dataset objects to manipulate them using the **Data API**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRnXTCg_8nRM",
        "colab_type": "text"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbcckhe58s5S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "6c5dd60c-7358-496c-f7a4-17f517341bdc"
      },
      "source": [
        "import sys\n",
        "assert sys.version_info >= (3, 5)  # Python ≥3.5 is required\n",
        "\n",
        "import sklearn \n",
        "assert sklearn.__version__ >= \"0.20\"  # Scikit-Learn ≥0.20 is required\n",
        "\n",
        "# %tensorflow_version only exists in Colab.\n",
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "  IS_COLAB = True\n",
        "except Exception:\n",
        "  IS_COLAB = False\n",
        "  pass\n",
        "\n",
        "# TensorFlow ≥2.0 is required\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "assert tf.__version__ >= '2.0'\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "if not tf.config.list_physical_devices('GPU'):\n",
        "    print(\"No GPU was detected. LSTMs and CNNs can be very slow without a GPU.\")\n",
        "    if IS_COLAB:\n",
        "        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "No GPU was detected. LSTMs and CNNs can be very slow without a GPU.\n",
            "Go to Runtime > Change runtime and select a GPU hardware accelerator.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkAn-27n9TcX",
        "colab_type": "text"
      },
      "source": [
        "## The Data API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ddjsd2PS9UfV",
        "colab_type": "text"
      },
      "source": [
        "The whole **Data API** revolves around the concept of a dataset: as you might suspect, this represents a sequence of data items. Usually you will use datasets that gradually read data from disk, but for simplicity let’s just create a dataset entirely in RAM using tf.data.Dataset.from_tensor_slices():"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXdlDh1P81as",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bb3c16d0-d0e7-4cb1-87e5-84fab468e2ee"
      },
      "source": [
        "X = tf.range(10)  # any data tensor\n",
        "dataset = tf.data.Dataset.from_tensor_slices(X)\n",
        "dataset"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset shapes: (), types: tf.int32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYxStsF7-LeT",
        "colab_type": "text"
      },
      "source": [
        "The from_tensor_slices() function takes a tensor and creates a tf.data.Dataset whose elements are all the slices of X (along the first dimension), so this dataset contains 10 items: tensors 0, 1, 2, …, 9."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftUX4SMx-A7h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "8a4e911b-2fa5-402f-8a5f-21da1945262a"
      },
      "source": [
        "for item in dataset:\n",
        "  print(item)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(0, shape=(), dtype=int32)\n",
            "tf.Tensor(1, shape=(), dtype=int32)\n",
            "tf.Tensor(2, shape=(), dtype=int32)\n",
            "tf.Tensor(3, shape=(), dtype=int32)\n",
            "tf.Tensor(4, shape=(), dtype=int32)\n",
            "tf.Tensor(5, shape=(), dtype=int32)\n",
            "tf.Tensor(6, shape=(), dtype=int32)\n",
            "tf.Tensor(7, shape=(), dtype=int32)\n",
            "tf.Tensor(8, shape=(), dtype=int32)\n",
            "tf.Tensor(9, shape=(), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9589xSI-Y5L",
        "colab_type": "text"
      },
      "source": [
        "Equivalently"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBLrXYbO-Suk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "ab48281d-3726-4a27-e00a-66a5d8bc6d38"
      },
      "source": [
        "dataset = tf.data.Dataset.range(10)\n",
        "for item in dataset:\n",
        "  print(item)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(0, shape=(), dtype=int64)\n",
            "tf.Tensor(1, shape=(), dtype=int64)\n",
            "tf.Tensor(2, shape=(), dtype=int64)\n",
            "tf.Tensor(3, shape=(), dtype=int64)\n",
            "tf.Tensor(4, shape=(), dtype=int64)\n",
            "tf.Tensor(5, shape=(), dtype=int64)\n",
            "tf.Tensor(6, shape=(), dtype=int64)\n",
            "tf.Tensor(7, shape=(), dtype=int64)\n",
            "tf.Tensor(8, shape=(), dtype=int64)\n",
            "tf.Tensor(9, shape=(), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rf5evy05-wLi",
        "colab_type": "text"
      },
      "source": [
        "### Chaining Transformations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hO-G1Hzt-zaT",
        "colab_type": "text"
      },
      "source": [
        "Once you have a dataset, you can apply all sorts of transformations to it by calling its transformation methods. Each method returns a new dataset, so you can chain transformations like this.\n",
        "\n",
        "<img src='https://github.com/rahiakela/img-repo/blob/master/hands-on-machine-learning-keras-tensorflow/chaining-dataset-transformations.png?raw=1' width='800'/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_chc0Ee-huU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "d2eb9b10-4f58-487d-acb0-c9b389cd1931"
      },
      "source": [
        "dataset = dataset.repeat(3).batch(7)\n",
        "for item in dataset:\n",
        "  print(item)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([0 1 2 3 4 5 6], shape=(7,), dtype=int64)\n",
            "tf.Tensor([7 8 9 0 1 2 3], shape=(7,), dtype=int64)\n",
            "tf.Tensor([4 5 6 7 8 9 0], shape=(7,), dtype=int64)\n",
            "tf.Tensor([1 2 3 4 5 6 7], shape=(7,), dtype=int64)\n",
            "tf.Tensor([8 9], shape=(2,), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSEHyhg_AArS",
        "colab_type": "text"
      },
      "source": [
        "We first call the repeat() method on the original dataset, and it returns a new dataset that will repeat the items of the original dataset 3 times. Of course, this will not copy the whole data in memory 3 times! In fact, if you call this method with no arguments, the new dataset will repeat the source dataset forever. Then we call the batch() method on this new dataset, and again this creates a new dataset. This one will group the items of the previous dataset in batches of 7 items.\n",
        "\n",
        "Finally, we iterate over the items of this final dataset. As you can see, the batch() method had to output a final batch of size 2 instead of 7, but you can call it with drop_remainder=True if you want it to drop this final batch so that all batches have the exact same size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOFkgio3_b_R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "e16dba26-8661-4bf4-bfe6-c4645772e185"
      },
      "source": [
        "dataset = tf.data.Dataset.range(10)\n",
        "dataset = dataset.repeat(5).batch(9)\n",
        "for item in dataset:\n",
        "  print(item)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([0 1 2 3 4 5 6 7 8], shape=(9,), dtype=int64)\n",
            "tf.Tensor([9 0 1 2 3 4 5 6 7], shape=(9,), dtype=int64)\n",
            "tf.Tensor([8 9 0 1 2 3 4 5 6], shape=(9,), dtype=int64)\n",
            "tf.Tensor([7 8 9 0 1 2 3 4 5], shape=(9,), dtype=int64)\n",
            "tf.Tensor([6 7 8 9 0 1 2 3 4], shape=(9,), dtype=int64)\n",
            "tf.Tensor([5 6 7 8 9], shape=(5,), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPvEIWcR_l-H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "675335ed-4f5f-45de-d289-a5e5e838d85f"
      },
      "source": [
        "dataset = tf.data.Dataset.range(10)\n",
        "dataset = dataset.repeat(5).batch(9, drop_remainder=True)  # discard the remainder\n",
        "for item in dataset:\n",
        "  print(item)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([0 1 2 3 4 5 6 7 8], shape=(9,), dtype=int64)\n",
            "tf.Tensor([9 0 1 2 3 4 5 6 7], shape=(9,), dtype=int64)\n",
            "tf.Tensor([8 9 0 1 2 3 4 5 6], shape=(9,), dtype=int64)\n",
            "tf.Tensor([7 8 9 0 1 2 3 4 5], shape=(9,), dtype=int64)\n",
            "tf.Tensor([6 7 8 9 0 1 2 3 4], shape=(9,), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zdo6O7HrBttP",
        "colab_type": "text"
      },
      "source": [
        "You can also apply any transformation you want to the items by calling the map() method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDL2p_E9A11n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "23ecdf53-8d15-49b1-9931-34692bd5c044"
      },
      "source": [
        "dataset = dataset.map(lambda x: x * 2)\n",
        "for item in dataset:\n",
        "  print(item)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([ 0  2  4  6  8 10 12 14 16], shape=(9,), dtype=int64)\n",
            "tf.Tensor([18  0  2  4  6  8 10 12 14], shape=(9,), dtype=int64)\n",
            "tf.Tensor([16 18  0  2  4  6  8 10 12], shape=(9,), dtype=int64)\n",
            "tf.Tensor([14 16 18  0  2  4  6  8 10], shape=(9,), dtype=int64)\n",
            "tf.Tensor([12 14 16 18  0  2  4  6  8], shape=(9,), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3x3nEvdwCKYD",
        "colab_type": "text"
      },
      "source": [
        "This function is the one you will call to apply any preprocessing you want to your data. Sometimes, this will include computations that can be quite intensive, such as reshaping or rotating an image, so you will usually want to spawn multiple threads to speed things up: it’s as simple as setting the num_parallel_calls argument.\n",
        "\n",
        "While the map() applies a transformation to each item, the apply() method applies a transformation to the dataset as a whole.\n",
        "\n",
        "For example, the following code “unbatches” the dataset, by applying the unbatch() function to the dataset.Each item in the new dataset will be a single integer tensor instead of a batch of 7 integers:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSS5cp1NB783",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "outputId": "fb4ada3f-59c0-49fe-b014-aa1fe9cf51a0"
      },
      "source": [
        "dataset1 = tf.data.Dataset.range(10)\n",
        "dataset1 = dataset1.repeat(5).batch(9, drop_remainder=True)  # discard the remainder\n",
        "dataset1 = dataset1.apply(tf.data.experimental.unbatch())\n",
        "for item in dataset1:\n",
        "  print(item)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(0, shape=(), dtype=int64)\n",
            "tf.Tensor(1, shape=(), dtype=int64)\n",
            "tf.Tensor(2, shape=(), dtype=int64)\n",
            "tf.Tensor(3, shape=(), dtype=int64)\n",
            "tf.Tensor(4, shape=(), dtype=int64)\n",
            "tf.Tensor(5, shape=(), dtype=int64)\n",
            "tf.Tensor(6, shape=(), dtype=int64)\n",
            "tf.Tensor(7, shape=(), dtype=int64)\n",
            "tf.Tensor(8, shape=(), dtype=int64)\n",
            "tf.Tensor(9, shape=(), dtype=int64)\n",
            "tf.Tensor(0, shape=(), dtype=int64)\n",
            "tf.Tensor(1, shape=(), dtype=int64)\n",
            "tf.Tensor(2, shape=(), dtype=int64)\n",
            "tf.Tensor(3, shape=(), dtype=int64)\n",
            "tf.Tensor(4, shape=(), dtype=int64)\n",
            "tf.Tensor(5, shape=(), dtype=int64)\n",
            "tf.Tensor(6, shape=(), dtype=int64)\n",
            "tf.Tensor(7, shape=(), dtype=int64)\n",
            "tf.Tensor(8, shape=(), dtype=int64)\n",
            "tf.Tensor(9, shape=(), dtype=int64)\n",
            "tf.Tensor(0, shape=(), dtype=int64)\n",
            "tf.Tensor(1, shape=(), dtype=int64)\n",
            "tf.Tensor(2, shape=(), dtype=int64)\n",
            "tf.Tensor(3, shape=(), dtype=int64)\n",
            "tf.Tensor(4, shape=(), dtype=int64)\n",
            "tf.Tensor(5, shape=(), dtype=int64)\n",
            "tf.Tensor(6, shape=(), dtype=int64)\n",
            "tf.Tensor(7, shape=(), dtype=int64)\n",
            "tf.Tensor(8, shape=(), dtype=int64)\n",
            "tf.Tensor(9, shape=(), dtype=int64)\n",
            "tf.Tensor(0, shape=(), dtype=int64)\n",
            "tf.Tensor(1, shape=(), dtype=int64)\n",
            "tf.Tensor(2, shape=(), dtype=int64)\n",
            "tf.Tensor(3, shape=(), dtype=int64)\n",
            "tf.Tensor(4, shape=(), dtype=int64)\n",
            "tf.Tensor(5, shape=(), dtype=int64)\n",
            "tf.Tensor(6, shape=(), dtype=int64)\n",
            "tf.Tensor(7, shape=(), dtype=int64)\n",
            "tf.Tensor(8, shape=(), dtype=int64)\n",
            "tf.Tensor(9, shape=(), dtype=int64)\n",
            "tf.Tensor(0, shape=(), dtype=int64)\n",
            "tf.Tensor(1, shape=(), dtype=int64)\n",
            "tf.Tensor(2, shape=(), dtype=int64)\n",
            "tf.Tensor(3, shape=(), dtype=int64)\n",
            "tf.Tensor(4, shape=(), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfoLVL__D6eQ",
        "colab_type": "text"
      },
      "source": [
        "It is also possible to simply filter the dataset using the filter() method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CK5_GaJID7VQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "outputId": "b5305689-477f-4d4d-9d9e-616e5151cb27"
      },
      "source": [
        "dataset1 = dataset1.filter(lambda x: x < 5)\n",
        "for item in dataset1:\n",
        "  print(item)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(0, shape=(), dtype=int64)\n",
            "tf.Tensor(1, shape=(), dtype=int64)\n",
            "tf.Tensor(2, shape=(), dtype=int64)\n",
            "tf.Tensor(3, shape=(), dtype=int64)\n",
            "tf.Tensor(4, shape=(), dtype=int64)\n",
            "tf.Tensor(0, shape=(), dtype=int64)\n",
            "tf.Tensor(1, shape=(), dtype=int64)\n",
            "tf.Tensor(2, shape=(), dtype=int64)\n",
            "tf.Tensor(3, shape=(), dtype=int64)\n",
            "tf.Tensor(4, shape=(), dtype=int64)\n",
            "tf.Tensor(0, shape=(), dtype=int64)\n",
            "tf.Tensor(1, shape=(), dtype=int64)\n",
            "tf.Tensor(2, shape=(), dtype=int64)\n",
            "tf.Tensor(3, shape=(), dtype=int64)\n",
            "tf.Tensor(4, shape=(), dtype=int64)\n",
            "tf.Tensor(0, shape=(), dtype=int64)\n",
            "tf.Tensor(1, shape=(), dtype=int64)\n",
            "tf.Tensor(2, shape=(), dtype=int64)\n",
            "tf.Tensor(3, shape=(), dtype=int64)\n",
            "tf.Tensor(4, shape=(), dtype=int64)\n",
            "tf.Tensor(0, shape=(), dtype=int64)\n",
            "tf.Tensor(1, shape=(), dtype=int64)\n",
            "tf.Tensor(2, shape=(), dtype=int64)\n",
            "tf.Tensor(3, shape=(), dtype=int64)\n",
            "tf.Tensor(4, shape=(), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poeMGLINEfI8",
        "colab_type": "text"
      },
      "source": [
        "You will often want to look at just a few items from a dataset. You can use the take() method for that:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCYKZLAqCrPw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "e801a59a-1bda-4e80-a8bb-f9b91b48df83"
      },
      "source": [
        "for item in dataset1.take(3):\n",
        "  print(item)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(0, shape=(), dtype=int64)\n",
            "tf.Tensor(1, shape=(), dtype=int64)\n",
            "tf.Tensor(2, shape=(), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmX4ZKD5EtS9",
        "colab_type": "text"
      },
      "source": [
        "### Shuffling the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5YVRd26EuTL",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNwbGz3sEmsy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}