{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1_convolutional_and_pooling_layers.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMUBK2rQf6PN7LdE1N23k/h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/hands-on-machine-learning-with-scikit-learn-keras-and-tensorflow/blob/14-deep-computer-vision-using-convolutional-neural-networks/1_convolutional_and_pooling_layers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LERORaqtZieL",
        "colab_type": "text"
      },
      "source": [
        "# Deep Computer Vision: Convolutional & Pooling Layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2PAOpbHZ15r",
        "colab_type": "text"
      },
      "source": [
        "Although IBM’s Deep Blue supercomputer beat the chess world champion Garry Kasparov back in 1996, it wasn’t until fairly recently that computers were able to reliably perform seemingly trivial tasks such as detecting a puppy in a picture or recognizing spoken words. \n",
        "\n",
        "Why are these tasks so effortless to us humans? \n",
        "\n",
        "The answer lies in the fact that perception largely takes place outside the realm of our consciousness, within specialized visual, auditory, and other sensory modules in our brains. By the time sensory information reaches our consciousness, it is already adorned with high-level features.\n",
        "\n",
        "For example, when you look at a picture of a cute puppy, you cannot choose\n",
        "not to see the puppy, not to notice its cuteness. Nor can you explain how you recognize a cute puppy; it’s just obvious to you. Thus, we cannot trust our subjective experience: perception is not trivial at all, and to understand it we must look at how the sensory modules work.\n",
        "\n",
        "Convolutional neural networks (CNNs) emerged from the study of the brain’s visual cortex, and they have been used in image recognition since the 1980s. \n",
        "\n",
        "In the last few years, thanks to the increase in computational power, the amount of available training data, and the tricks for training deep nets, CNNs have managed to achieve superhuman performance on some complex visual tasks. They power image search services, self-driving cars, automatic video classification systems, and more. \n",
        "\n",
        "Moreover, CNNs are not restricted to visual perception: they are also successful at many other tasks, such as voice recognition and natural language processing. However, we will focus on visual applications for now.\n",
        "\n",
        "We will explore where CNNs came from, what their building blocks look like, and how to implement them using TensorFlow and Keras. Then we will discuss\n",
        "some of the best CNN architectures, as well as other visual tasks, including:\n",
        "\n",
        "1. object detection (classifying multiple objects in an image and placing bounding boxes around them) \n",
        "2. and semantic segmentation (classifying each pixel according to the\n",
        "class of the object it belongs to)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tc9EXon5at_k",
        "colab_type": "text"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VToqS0smavOd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "5bacd304-dfee-40b2-872c-ed8b3735f0ed"
      },
      "source": [
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "try:\n",
        "    # %tensorflow_version only exists in Colab.\n",
        "    %tensorflow_version 2.x\n",
        "    IS_COLAB = True\n",
        "except Exception:\n",
        "    IS_COLAB = False\n",
        "\n",
        "# TensorFlow ≥2.0 is required\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "if not tf.config.list_physical_devices('GPU'):\n",
        "    print(\"No GPU was detected. LSTMs and CNNs can be very slow without a GPU.\")\n",
        "    if IS_COLAB:\n",
        "        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMBFSSWld5cw",
        "colab_type": "text"
      },
      "source": [
        "A couple utility functions to plot grayscale and RGB images:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWDMaCgxd44Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_image(image):\n",
        "    plt.imshow(image, cmap=\"gray\", interpolation=\"nearest\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "def plot_color_image(image):\n",
        "    plt.imshow(image, interpolation=\"nearest\")\n",
        "    plt.axis(\"off\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cy0mB8KJdCxW",
        "colab_type": "text"
      },
      "source": [
        "## What is a Convolution?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNfPh_dcdDsI",
        "colab_type": "text"
      },
      "source": [
        "The studies of the visual cortex inspired the [neocognitron](https://www.cs.princeton.edu/courses/archive/spr08/cos598B/Readings/Fukushima1980.pdf), introduced in 1980, which gradually evolved into what we now call convolutional neural networks. \n",
        "\n",
        "An important milestone was a [1998 paper](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf) by Yann LeCun et al. that introduced the famous LeNet-5 architecture, widely used by banks to recognize handwritten check numbers. This architecture has some building blocks, such as fully connected layers and sigmoid activation functions, but it also introduces two new building blocks: convolutional layers and pooling layers.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JumRHW-kdvwv",
        "colab_type": "text"
      },
      "source": [
        "## Convolutional Layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJIVivJzdzht",
        "colab_type": "text"
      },
      "source": [
        "The most important building block of a CNN is the convolutional layer: neurons in the first convolutional layer are not connected to every single pixel in the input image, but only to pixels in their receptive fields.\n",
        "\n",
        "In turn, each neuron in the second convolutional layer is connected only to neurons located within a small rectangle in the first layer.\n",
        "\n",
        "This architecture allows the network to concentrate on small low-level features in the first hidden layer, then assemble them into larger higher-level features in the next hidden layer, and so on. This hierarchical structure is common in real-world images, which is one of the reasons why CNNs work so well for image recognition.\n",
        "\n",
        "<img src='https://github.com/rahiakela/img-repo/blob/master/hands-on-machine-learning-keras-tensorflow/local-receptive-fields.png?raw=1' width='800'/>\n",
        "\n",
        "A neuron located in row i, column j of a given layer is connected to the outputs of the neurons in the previous layer located in rows $i$ to $j + f_{\\mathbf{h}} - 1$, columns $j$ to $j + f_{\\mathbf{w}} - 1$, where fh and fw are the height and width of the receptive field.\n",
        "\n",
        "<img src='https://github.com/rahiakela/img-repo/blob/master/hands-on-machine-learning-keras-tensorflow/zero-padding.png?raw=1' width='800'/>\n",
        "\n",
        "In order for a layer to have the same height and width as the previous layer, it is common to add zeros around the inputs, as shown in the diagram. This is called zero padding.\n",
        "\n",
        "It is also possible to connect a large input layer to a much smaller layer by spacing out the receptive fields.This dramatically reduces the model’s\n",
        "computational complexity. The shift from one receptive field to the next is called the stride.\n",
        "\n",
        "<img src='https://github.com/rahiakela/img-repo/blob/master/hands-on-machine-learning-keras-tensorflow/stride.png?raw=1' width='800'/>\n",
        "\n",
        "In the diagram, a 5 × 7 input layer (plus zero padding) is connected to a 3 × 4 layer, using 3 × 3 receptive fields and a stride of 2 (in this example the stride is the same in both directions, but it does not have to be so). A neuron located in row $i$, column $j$ in the upper layer is connected to the outputs of the neurons in the previous layer located in rows $i *  s_{\\mathbf{h}}$ to $i *  s_{\\mathbf{h}} + f_{\\mathbf{h}} -1$, columns $j *  s_{\\mathbf{w}}$ to $j *  s_{\\mathbf{w}} + f_{\\mathbf{w}} -1$, where $s_{\\mathbf{h}}$ and $s_{\\mathbf{w}}$ are the vertical and horizontal strides.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30ubP2RNeQum",
        "colab_type": "text"
      },
      "source": [
        "## Filters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlYlb0rtedfy",
        "colab_type": "text"
      },
      "source": [
        "A neuron’s weights can be represented as a small image the size of the receptive field.\n",
        "\n",
        "For example, the figure below shows two possible sets of weights, called filters (or convolution kernels). The first one is represented as a black square with a vertical white line in the middle (it is a 7 × 7 matrix full of 0s except for the central column, which is full of 1s); neurons using these weights will ignore everything in their receptive field except\n",
        "for the central vertical line (since all inputs will get multiplied by 0, except for the ones located in the central vertical line).\n",
        "\n",
        "The second filter is a black square with a horizontal white line in the middle. Once again, neurons using these weights will ignore everything in their receptive field except for the central horizontal line.\n",
        "\n",
        "<img src='https://github.com/rahiakela/img-repo/blob/master/hands-on-machine-learning-keras-tensorflow/feature-maps.png?raw=1' width='800'/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdX8JlPjgnen",
        "colab_type": "text"
      },
      "source": [
        "## Stacking Multiple Feature Maps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUBFbc-Rgoq0",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}