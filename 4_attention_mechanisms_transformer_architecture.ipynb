{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4-attention-mechanisms-transformer-architecture.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPQRHUfY9i4Hdqsn7AtAg1O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/hands-on-machine-learning-with-scikit-learn-keras-and-tensorflow/blob/16-natural-nanguage-processing-with-RNNs-and-Attention/4_attention_mechanisms_transformer_architecture.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLiYxU1MQMAC",
        "colab_type": "text"
      },
      "source": [
        "# Attention Mechanisms: The Transformer Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QsB8Y7ZQRE8",
        "colab_type": "text"
      },
      "source": [
        "Consider the path from the word “milk” to its translation “lait” below. it is quite long! \n",
        "\n",
        "This means that a representation of this word (along with all the other words) needs to be carried over many steps before it is actually used. Can’t we make this path shorter?\n",
        "\n",
        "<img src='https://github.com/rahiakela/img-repo/blob/master/hands-on-machine-learning-keras-tensorflow/simple-machine-translation-model.png?raw=1' width='800'/>\n",
        "\n",
        "This was the core idea in a groundbreaking [2014 paper](https://arxiv.org/abs/1409.0473) by Dzmitry Bahdanau et al. They introduced a technique that allowed the decoder to focus on the appropriate words (as encoded by the encoder) at each time step.\n",
        "\n",
        "For example, at the time step where the decoder needs to output the word “lait,” it will focus its attention on the word “milk.”\n",
        "\n",
        "This means that the path from an input word to its translation is now much shorter, so the short-term memory limitations of RNNs have much less impact.\n",
        "\n",
        "Attention mechanisms revolutionized neural machine translation and NLP in general), allowing a significant improvement in the state of the art, especially for long sentences (over 30 words).\n",
        "\n",
        "<img src='https://github.com/rahiakela/img-repo/blob/master/hands-on-machine-learning-keras-tensorflow/encoder–decoder-attention-model.png?raw=1' width='800'/>\n",
        "\n",
        "Instead of just sending the encoder’s final hidden state to the decoder (which is still done, although it is not shown in the figure), we now send all of its outputs to the decoder. \n",
        "\n",
        "At each time step, the decoder’s memory cell computes a weighted sum of all these encoder outputs: this determines which words it will focus on at this step. The weight α(t,i) is the weight of the ith encoder output at the tth decoder time step.\n",
        "\n",
        "For example, if the weight α(3,2) is much larger than the weights α(3,0) and α(3,1), then the decoder will pay much more attention to word number 2 (“milk”) than to the other two words, at least at this time step. \n",
        "\n",
        "The rest of the decoder works just like earlier: at each time step the memory cell receives the inputs we just discussed, plus the hidden state from the previous time step, and finally (although it is not represented in the diagram) it receives the target word from the previous time step (or at inference time, the output from the previous time step).\n",
        "\n",
        "But where do these α(t,i) weights come from? It’s actually pretty simple: they are generated by a type of small neural network called an alignment model (or an attention layer), which is trained jointly with the rest of the Encoder–Decoder model. This alignment model is illustrated on the righthand side.\n",
        "\n",
        "This layer outputs a score (or energy) for each encoder output (e.g., e(3, 2)): this score measures how well each output is aligned with the decoder’s previous hidden state.\n",
        "\n",
        "Finally, all the scores go through a softmax layer to get a final weight for each encoder output (e.g., α(3,2)). All the weights for a given decoder time step add up to 1 (since the\n",
        "softmax layer is not time-distributed). \n",
        "\n",
        "This particular attention mechanism is called Bahdanau attention.\n",
        "Since it concatenates the encoder output with the decoder’s previous hidden state, it is sometimes called concatenative attention (or additive attention)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxpL5lrJWJyx",
        "colab_type": "text"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMK3gpEjWLli",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "assert sys.version_info >= (3, 5)  # Python ≥3.5 is required\n",
        "\n",
        "import sklearn \n",
        "assert sklearn.__version__ >= \"0.20\"  # Scikit-Learn ≥0.20 is required\n",
        "\n",
        "# %tensorflow_version only exists in Colab.\n",
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "  IS_COLAB = True\n",
        "except Exception:\n",
        "  IS_COLAB = False\n",
        "  pass\n",
        "\n",
        "# TensorFlow ≥2.0 is required\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "assert tf.__version__ >= '2.0'\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "if not tf.config.list_physical_devices('GPU'):\n",
        "    print(\"No GPU was detected. LSTMs and CNNs can be very slow without a GPU.\")\n",
        "    if IS_COLAB:\n",
        "        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezUQK_s9WF7K",
        "colab_type": "text"
      },
      "source": [
        "## Visual Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DiN_g5DSPFw",
        "colab_type": "text"
      },
      "source": [
        "Attention mechanisms are now used for a variety of purposes. One of their first applications beyond NMT was in generating image captions using [visual attention](https://arxiv.org/abs/1502.03044).\n",
        "\n",
        "A convolutional neural network first processes the image and outputs some feature maps, then a decoder RNN equipped with an attention mechanism generates the caption, one word at a time. At each decoder time step (each word), the decoder uses the\n",
        "attention model to focus on just the right part of the image.\n",
        "\n",
        "For example, the model generated the caption “A woman is throwing a frisbee in a park,” and you can see what part of the input image the decoder focused its attention on when it was about to output the word “frisbee”: clearly, most of its attention was focused on the frisbee.\n",
        "\n",
        "<img src='https://github.com/rahiakela/img-repo/blob/master/hands-on-machine-learning-keras-tensorflow/visual-attention.png?raw=1' width='800'/>\n",
        "\n",
        "Attention mechanisms are so powerful that you can actually build state-of-the-art models using only attention mechanisms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYYIUhsuY7oX",
        "colab_type": "text"
      },
      "source": [
        "## Attention Is All You Need: The Transformer Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9S3HNDs4Y8ts",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}